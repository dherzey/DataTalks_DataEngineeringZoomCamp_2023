{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook for data ingestion\n",
    "This notebook will include test scripts to ingest the necessary data from various web sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Bechdel test of movies\n",
    "Scrape data from http://bechdeltest.com/ using its given API. Note that according to the owner, we should avoid calling the `getAllMovies` module frequently due to a shared hosting plan. Due to this, I ran the get requests once and saved the copy as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>imdbid</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>0</td>\n",
       "      <td>416449.0</td>\n",
       "      <td>1271</td>\n",
       "      <td>300</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>3</td>\n",
       "      <td>419773.0</td>\n",
       "      <td>4834</td>\n",
       "      <td>Gespenster</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2</td>\n",
       "      <td>31679.0</td>\n",
       "      <td>5946</td>\n",
       "      <td>Mr. Smith Goes to Washington</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9801</th>\n",
       "      <td>3</td>\n",
       "      <td>12048234.0</td>\n",
       "      <td>10426</td>\n",
       "      <td>Save the Cinema</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>3</td>\n",
       "      <td>2382422.0</td>\n",
       "      <td>8099</td>\n",
       "      <td>Jacky in the kingdom of women</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>1</td>\n",
       "      <td>58461.0</td>\n",
       "      <td>661</td>\n",
       "      <td>Per un pugno di dollari (A Fisful of Dollars)</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7840</th>\n",
       "      <td>3</td>\n",
       "      <td>3104818.0</td>\n",
       "      <td>6724</td>\n",
       "      <td>Like Sunday, Like Rain</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6648</th>\n",
       "      <td>3</td>\n",
       "      <td>1205558.0</td>\n",
       "      <td>4089</td>\n",
       "      <td>Hick</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>3</td>\n",
       "      <td>381707.0</td>\n",
       "      <td>4298</td>\n",
       "      <td>White Chicks</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>3</td>\n",
       "      <td>3281548.0</td>\n",
       "      <td>8949</td>\n",
       "      <td>Little Women</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating      imdbid     id  \\\n",
       "4907       0    416449.0   1271   \n",
       "4790       3    419773.0   4834   \n",
       "440        2     31679.0   5946   \n",
       "9801       3  12048234.0  10426   \n",
       "7900       3   2382422.0   8099   \n",
       "1156       1     58461.0    661   \n",
       "7840       3   3104818.0   6724   \n",
       "6648       3   1205558.0   4089   \n",
       "4548       3    381707.0   4298   \n",
       "9286       3   3281548.0   8949   \n",
       "\n",
       "                                              title  year  \n",
       "4907                                            300  2006  \n",
       "4790                                     Gespenster  2005  \n",
       "440                    Mr. Smith Goes to Washington  1939  \n",
       "9801                                Save the Cinema  2022  \n",
       "7900                  Jacky in the kingdom of women  2014  \n",
       "1156  Per un pugno di dollari (A Fisful of Dollars)  1964  \n",
       "7840                         Like Sunday, Like Rain  2014  \n",
       "6648                                           Hick  2011  \n",
       "4548                                   White Chicks  2004  \n",
       "9286                                   Little Women  2019  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "main_dir = \"/home/jdtganding/Documents/data-engineering-zoomcamp/week_7_PROJECT/data\"\n",
    "\n",
    "# html = requests.get('http://bechdeltest.com/api/v1/getAllMovies').content\n",
    "# df = pd.read_json(io.StringIO(html.decode('utf-8')))\n",
    "# df.to_csv(bechdel_movies, index=None)\n",
    "\n",
    "bechdel_movies_df = pd.read_csv(f\"{main_dir}/BechdelTestMovies.csv\")\n",
    "bechdel_movies_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Oscars movie nominees and winners\n",
    "The Academy Awards has their own database found on https://awardsdatabase.oscars.org/. I scraped the whole database from the 1st Academy Awards up to the latest using `selenium` and saved the page source as a variable that can be read using `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "\n",
    "driver = webdriver.Firefox(options=options)\n",
    "driver.get(\"https://awardsdatabase.oscars.org/\") \n",
    "\n",
    "#select award categories\n",
    "driver.find_element(By.XPATH,\"//button[contains(@class,'awards-basicsrch-awardcategory')]\").click()\n",
    "driver.find_element(By.XPATH,\"//b[contains(text(),'Current Categories')]\").click()\n",
    "\n",
    "#select starting award year\n",
    "driver.find_element(By.XPATH,\"//button[contains(@class,'awards-advsrch-yearsfrom')]\").click()\n",
    "driver.find_element(By.XPATH,\"//div[@class='btn-group multiselect-btn-group open']//input[@value='1']\").click()\n",
    "\n",
    "#select ending award year\n",
    "driver.find_element(By.XPATH,\"//button[contains(@class,'awards-advsrch-yearsto')]\").click()\n",
    "year_latest = len(driver.find_elements(By.XPATH,\"//div[@class='btn-group multiselect-btn-group open']//li\"))-2\n",
    "driver.find_element(By.XPATH,f\"//div[@class='btn-group multiselect-btn-group open']//input[@value='{year_latest}']\").click()\n",
    "\n",
    "#search to view results\n",
    "driver.find_element(By.XPATH,'//*[@id=\"btnbasicsearch\"]').click()\n",
    "\n",
    "#wait for all results to show\n",
    "time.sleep(60)\n",
    "\n",
    "#get html source for BeautifulSoup extraction\n",
    "page_source = driver.page_source\n",
    "\n",
    "#close driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BeautifulSoup to extract elements and clean the page source\n",
    "I saved the data for `id=resultscontainer` to avoid the long execution of the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(page_source, \"lxml\")\n",
    "# results_container = soup.find('div', {'id':'resultscontainer'})\n",
    "\n",
    "# with open (f\"{main_dir}/results.txt\", \"w\") as file:\n",
    "#     file.write(str(results_container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_container = open(f\"{main_dir}/results.txt\", \"r\")\n",
    "results_container = BeautifulSoup(results_container, 'lxml')\n",
    "\n",
    "award_year_all = results_container.find_all('div',class_='awards-result-chron result-group group-awardcategory-chron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oscars_results_dict = {}\n",
    "\n",
    "for award_year_group in award_year_all:\n",
    "\n",
    "    #find the award year title\n",
    "    award_year = award_year_group.find('div',class_='result-group-title')\\\n",
    "                                 .get_text(strip=True)\n",
    "    \n",
    "    #award category result subgroup (each contains award title and nominees)\n",
    "    award_category_all = award_year_group.find_all('div',class_='result-subgroup subgroup-awardcategory-chron')\n",
    "\n",
    "    award_subgroup_dict = {}\n",
    "    for award_category_group in award_category_all:\n",
    "\n",
    "        #dictionary to contain movie lists\n",
    "        movies_dict = {\"nominated\":[], \"won\":[]}\n",
    "\n",
    "        #find award title\n",
    "        award_title = award_category_group.find('div',class_='result-subgroup-title')\\\n",
    "                                          .get_text(strip=True)\n",
    "        \n",
    "        try:\n",
    "            #find nominated movies\n",
    "            movies = [movie.get_text(strip=True) for movie in award_category_group.find_all('div', class_='awards-result-film-title')]\n",
    "\n",
    "            #find winning movie\n",
    "            winner_group = award_category_group.find('span', {'title':'Winner'})\\\n",
    "                                               .find_next_sibling('div')\n",
    "\n",
    "            movies_dict[\"won\"] = [movie.get_text(strip=True) for movie in winner_group.find_all('div', class_='awards-result-film-title')] \n",
    "\n",
    "            #remove duplicates and the winner from nominated list\n",
    "            movies_dict[\"nominated\"] = list(set(movies) - set(movies_dict[\"won\"])) \n",
    "            \n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        award_subgroup_dict[award_title] = movies_dict\n",
    "    oscars_results_dict[award_year] = award_subgroup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the raw file as a json \n",
    "import json\n",
    "\n",
    "with open (f\"{main_dir}/oscars_results_raw.json\", \"w\", encoding='utf-8') as output:\n",
    "    json.dump(oscars_results_dict, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nominated': ['Dr. Jekyll and Mr. Hyde', 'The Guardsman'],\n",
       " 'won': ['The Champ']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oscars_results_dict['1931/32 (5th)']['ACTOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1927/28 (1st)', '1928/29 (2nd)', '1929/30 (3rd)', '1930/31 (4th)', '1931/32 (5th)', '1932/33 (6th)', '1934 (7th)', '1935 (8th)', '1936 (9th)', '1937 (10th)', '1938 (11th)', '1939 (12th)', '1940 (13th)', '1941 (14th)', '1942 (15th)', '1943 (16th)', '1944 (17th)', '1945 (18th)', '1946 (19th)', '1947 (20th)', '1948 (21st)', '1949 (22nd)', '1950 (23rd)', '1951 (24th)', '1952 (25th)', '1953 (26th)', '1954 (27th)', '1955 (28th)', '1956 (29th)', '1957 (30th)', '1958 (31st)', '1959 (32nd)', '1960 (33rd)', '1961 (34th)', '1962 (35th)', '1963 (36th)', '1964 (37th)', '1965 (38th)', '1966 (39th)', '1967 (40th)', '1968 (41st)', '1969 (42nd)', '1970 (43rd)', '1971 (44th)', '1972 (45th)', '1973 (46th)', '1974 (47th)', '1975 (48th)', '1976 (49th)', '1977 (50th)', '1978 (51st)', '1979 (52nd)', '1980 (53rd)', '1981 (54th)', '1982 (55th)', '1983 (56th)', '1984 (57th)', '1985 (58th)', '1986 (59th)', '1987 (60th)', '1988 (61st)', '1989 (62nd)', '1990 (63rd)', '1991 (64th)', '1992 (65th)', '1993 (66th)', '1994 (67th)', '1995 (68th)', '1996 (69th)', '1997 (70th)', '1998 (71st)', '1999 (72nd)', '2000 (73rd)', '2001 (74th)', '2002 (75th)', '2003 (76th)', '2004 (77th)', '2005 (78th)', '2006 (79th)', '2007 (80th)', '2008 (81st)', '2009 (82nd)', '2010 (83rd)', '2011 (84th)', '2012 (85th)', '2013 (86th)', '2014 (87th)', '2015 (88th)', '2016 (89th)', '2017 (90th)', '2018 (91st)', '2019 (92nd)', '2020 (93rd)', '2021 (94th)', '2022 (95th)'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oscars_results_dict.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform json into structured format such as csv\n",
    "We would want the following structure for our dataframe:\n",
    "```python\n",
    "df_structure = {\n",
    "    \"AwardYear\":[],\n",
    "    \"AwardCeremonyNum\":[],\n",
    "    \"Movie\":[],\n",
    "    \"AwardCategory\":[],\n",
    "    \"AwardStatus\":[]\n",
    "}\n",
    "```\n",
    "\n",
    "- `AwardYear`: the year the award was received\n",
    "- `AwardCeremonyNum`: the nth annual ceremony award\n",
    "- `Movie`: the title of the nominated film\n",
    "- `AwardCategory`: the category the film was nominated for\n",
    "- `AwardStatus`: whether the film was only nominated or had won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for key, value in oscars_results_dict.items():\n",
    "\n",
    "    df_structure = {}\n",
    "\n",
    "    #separate key strings to extract year\n",
    "    key_split = key.split(\" \")\n",
    "    df_structure['AwardYear'] = key_split[0]\n",
    "    df_structure['AwardCeremonyNum'] = re.findall(r'\\d+',key_split[1])[0]\n",
    "\n",
    "    #extract all movies per award year\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AwardYear': '2022', 'AwardCeremonyNum': '95'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_structure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
