{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook for data ingestion\n",
    "This notebook will include test scripts to ingest the necessary data from various web sources."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Bechdel test of movies\n",
    "Scrape data from http://bechdeltest.com/ using its given API. Note that according to the owner, we should avoid calling the `getAllMovies` module frequently due to a shared hosting plan. Due to this, I ran the get requests once and saved the copy as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>imdbid</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>3</td>\n",
       "      <td>348226.0</td>\n",
       "      <td>6867</td>\n",
       "      <td>Tomie: Saishuu-sho - kindan no kajitsu</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>3</td>\n",
       "      <td>11334312.0</td>\n",
       "      <td>9507</td>\n",
       "      <td>Final Level: Escaping Rancala, The</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>3</td>\n",
       "      <td>1724965.0</td>\n",
       "      <td>6668</td>\n",
       "      <td>Innocence</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>3</td>\n",
       "      <td>109913.0</td>\n",
       "      <td>1788</td>\n",
       "      <td>Go Fish</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>0</td>\n",
       "      <td>107214.0</td>\n",
       "      <td>4337</td>\n",
       "      <td>Indien</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>1</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>5751</td>\n",
       "      <td>Revenge of the Nerds</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>1</td>\n",
       "      <td>871197.0</td>\n",
       "      <td>7121</td>\n",
       "      <td>&amp;quot;Masters of Horror&amp;quot; Right to Die</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>1</td>\n",
       "      <td>1597522.0</td>\n",
       "      <td>6993</td>\n",
       "      <td>Asterix and Obelix: God Save Britannia</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>3</td>\n",
       "      <td>785532.0</td>\n",
       "      <td>7114</td>\n",
       "      <td>&amp;quot;Masters of Horror&amp;quot; Pro-Life</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>3</td>\n",
       "      <td>4009278.0</td>\n",
       "      <td>7881</td>\n",
       "      <td>Intruders</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating      imdbid    id                                       title  \\\n",
       "4209       3    348226.0  6867      Tomie: Saishuu-sho - kindan no kajitsu   \n",
       "9371       3  11334312.0  9507          Final Level: Escaping Rancala, The   \n",
       "7836       3   1724965.0  6668                                   Innocence   \n",
       "2975       3    109913.0  1788                                     Go Fish   \n",
       "2896       0    107214.0  4337                                      Indien   \n",
       "2144       1     88000.0  5751                        Revenge of the Nerds   \n",
       "5359       1    871197.0  7121  &quot;Masters of Horror&quot; Right to Die   \n",
       "7093       1   1597522.0  6993      Asterix and Obelix: God Save Britannia   \n",
       "5081       3    785532.0  7114      &quot;Masters of Horror&quot; Pro-Life   \n",
       "8226       3   4009278.0  7881                                   Intruders   \n",
       "\n",
       "      year  \n",
       "4209  2002  \n",
       "9371  2019  \n",
       "7836  2014  \n",
       "2975  1994  \n",
       "2896  1993  \n",
       "2144  1984  \n",
       "5359  2007  \n",
       "7093  2012  \n",
       "5081  2006  \n",
       "8226  2015  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "bechdel_movies = '/home/jdtganding/Documents/data-engineering-zoomcamp/week_7_PROJECT/data/BechdelTestMovies.csv'\n",
    "\n",
    "# html = requests.get('http://bechdeltest.com/api/v1/getAllMovies').content\n",
    "# df = pd.read_json(io.StringIO(html.decode('utf-8')))\n",
    "# df.to_csv(bechdel_movies, index=None)\n",
    "\n",
    "bechdel_movies_df = pd.read_csv(bechdel_movies)\n",
    "bechdel_movies_df.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Oscars movie nominees and winners\n",
    "The Academy Awards has their own database found on https://awardsdatabase.oscars.org/. I scraped the whole database from the 1st Academy Awards up to the latest using `selenium` and saved the page source as a variable that can be read using `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "\n",
    "driver = webdriver.Firefox(options=options)\n",
    "driver.get(\"https://awardsdatabase.oscars.org/\") \n",
    "\n",
    "#select award categories\n",
    "driver.find_element(By.XPATH,\"//button[contains(@class,'awards-basicsrch-awardcategory')]\").click()\n",
    "driver.find_element(By.XPATH,\"//b[contains(text(),'Current Categories')]\").click()\n",
    "\n",
    "#select starting award year\n",
    "driver.find_element(By.XPATH,\"//button[contains(@class,'awards-advsrch-yearsfrom')]\").click()\n",
    "driver.find_element(By.XPATH,\"//div[@class='btn-group multiselect-btn-group open']//input[@value='1']\").click()\n",
    "\n",
    "#select ending award year\n",
    "driver.find_element(By.XPATH,\"//button[contains(@class,'awards-advsrch-yearsto')]\").click()\n",
    "year_latest = len(driver.find_elements(By.XPATH,\"//div[@class='btn-group multiselect-btn-group open']//li\"))-2\n",
    "driver.find_element(By.XPATH,f\"//div[@class='btn-group multiselect-btn-group open']//input[@value='{year_latest}']\").click()\n",
    "\n",
    "#search to view results\n",
    "driver.find_element(By.XPATH,'//*[@id=\"btnbasicsearch\"]').click()\n",
    "\n",
    "#wait for all results to show\n",
    "time.sleep(60)\n",
    "\n",
    "#get html source for BeautifulSoup extraction\n",
    "page_source = driver.page_source\n",
    "\n",
    "#close driver\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BeautifulSoup to extract elements and clean the page source\n",
    "I saved the data for `id=resultscontainer` to avoid the long execution of the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_source, \"lxml\")\n",
    "results_container = soup.find('div', {'id':'resultscontainer'})\n",
    "\n",
    "main_dir = \"/home/jdtganding/Documents/data-engineering-zoomcamp/week_7_PROJECT/data\"\n",
    "with open (f\"{main_dir}/results.txt\", \"w\") as file:\n",
    "    file.write(str(results_container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = open(f\"{main_dir}/results.txt\", \"r\")\n",
    "results = BeautifulSoup(results, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1927/28 (1st)\n",
      "1928/29 (2nd)\n",
      "1929/30 (3rd)\n",
      "1930/31 (4th)\n",
      "1931/32 (5th)\n",
      "1932/33 (6th)\n",
      "1934 (7th)\n",
      "1935 (8th)\n",
      "1936 (9th)\n",
      "1937 (10th)\n",
      "1938 (11th)\n",
      "1939 (12th)\n",
      "1940 (13th)\n",
      "1941 (14th)\n",
      "1942 (15th)\n",
      "1943 (16th)\n",
      "1944 (17th)\n",
      "1945 (18th)\n",
      "1946 (19th)\n",
      "1947 (20th)\n",
      "1948 (21st)\n",
      "1949 (22nd)\n",
      "1950 (23rd)\n",
      "1951 (24th)\n",
      "1952 (25th)\n",
      "1953 (26th)\n",
      "1954 (27th)\n",
      "1955 (28th)\n",
      "1956 (29th)\n",
      "1957 (30th)\n",
      "1958 (31st)\n",
      "1959 (32nd)\n",
      "1960 (33rd)\n",
      "1961 (34th)\n",
      "1962 (35th)\n",
      "1963 (36th)\n",
      "1964 (37th)\n",
      "1965 (38th)\n",
      "1966 (39th)\n",
      "1967 (40th)\n",
      "1968 (41st)\n",
      "1969 (42nd)\n",
      "1970 (43rd)\n",
      "1971 (44th)\n",
      "1972 (45th)\n",
      "1973 (46th)\n",
      "1974 (47th)\n",
      "1975 (48th)\n",
      "1976 (49th)\n",
      "1977 (50th)\n",
      "1978 (51st)\n",
      "1979 (52nd)\n",
      "1980 (53rd)\n",
      "1981 (54th)\n",
      "1982 (55th)\n",
      "1983 (56th)\n",
      "1984 (57th)\n",
      "1985 (58th)\n",
      "1986 (59th)\n",
      "1987 (60th)\n",
      "1988 (61st)\n",
      "1989 (62nd)\n",
      "1990 (63rd)\n",
      "1991 (64th)\n",
      "1992 (65th)\n",
      "1993 (66th)\n",
      "1994 (67th)\n",
      "1995 (68th)\n",
      "1996 (69th)\n",
      "1997 (70th)\n",
      "1998 (71st)\n",
      "1999 (72nd)\n",
      "2000 (73rd)\n",
      "2001 (74th)\n",
      "2002 (75th)\n",
      "2003 (76th)\n",
      "2004 (77th)\n",
      "2005 (78th)\n",
      "2006 (79th)\n",
      "2007 (80th)\n",
      "2008 (81st)\n",
      "2009 (82nd)\n",
      "2010 (83rd)\n",
      "2011 (84th)\n",
      "2012 (85th)\n",
      "2013 (86th)\n",
      "2014 (87th)\n",
      "2015 (88th)\n",
      "2016 (89th)\n",
      "2017 (90th)\n",
      "2018 (91st)\n",
      "2019 (92nd)\n",
      "2020 (93rd)\n",
      "2021 (94th)\n",
      "2022 (95th)\n"
     ]
    }
   ],
   "source": [
    "award_years = results.find_all('div', class_='awards-result-chron result-group group-awardcategory-chron')\n",
    "\n",
    "for award_year in award_years:\n",
    "    ceremony_year = award_year.find('div', class_='result-group-title').find('a').text\n",
    "    print(ceremony_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
